{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f3c76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47124a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x110cdb4f0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x111541870> root_client=<openai.OpenAI object at 0x1090efbe0> root_async_client=<openai.AsyncOpenAI object at 0x110cdbb50> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"**Agentic AI** refers to artificial intelligence systems designed with a degree of autonomy and proactive decision-making capabilities, enabling them to act independently to achieve specific goals or perform tasks on behalf of users or organizations. Unlike traditional AI systems that primarily react to inputs and follow predefined instructions, agentic AI possesses characteristics akin to agency, such as:\\n\\n1. **Autonomy**: The ability to operate without continuous human intervention, making decisions based on its programming and learned experiences.\\n2. **Goal-Oriented Behavior**: Setting and pursuing objectives, adjusting strategies as needed to accomplish desired outcomes.\\n3. **Learning and Adaptation**: Continuously improving performance through machine learning, adapting to new information and changing environments.\\n4. **Interaction and Communication**: Engaging with users and other systems through natural language processing, APIs, or other interfaces to facilitate collaboration and information exchange.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Decision-Making Capability**: Agentic AI can analyze data, consider potential actions, and make informed decisions to achieve its goals.\\n2. **Proactivity**: Instead of waiting for explicit instructions, it can anticipate needs or problems and take initiative to address them.\\n3. **Interactivity**: Effective communication with humans and other systems to receive feedback, clarify objectives, and refine actions.\\n4. **Adaptability**: Ability to learn from experiences, adjust strategies, and handle unforeseen circumstances.\\n\\n### Examples of Agentic AI\\n\\n- **Virtual Assistants**: Advanced virtual assistants like Apple's Siri, Amazon's Alexa, or Google's Assistant are evolving toward greater agency by proactively managing schedules, optimizing routes, and integrating with various services to perform tasks without explicit prompts.\\n  \\n- **Autonomous Vehicles**: Self-driving cars exemplify agentic AI by navigating roads, making real-time decisions based on traffic conditions, and ensuring passenger safety with minimal human input.\\n  \\n- **Robotic Process Automation (RPA)**: In business settings, agentic AI-powered bots can handle repetitive tasks, such as data entry, invoice processing, and customer service inquiries, autonomously improving efficiency.\\n  \\n- **Smart Home Systems**: AI systems that manage heating, lighting, security, and appliances by learning user preferences and adjusting settings proactively to enhance comfort and energy efficiency.\\n\\n### Applications and Benefits\\n\\n- **Efficiency and Productivity**: By automating complex and time-consuming tasks, agentic AI can significantly boost operational efficiency and allow humans to focus on higher-level activities.\\n  \\n- **Personalization**: Tailoring experiences, services, and recommendations based on individual preferences and behaviors, enhancing user satisfaction and engagement.\\n  \\n- **Decision Support**: Providing insights and recommendations to aid human decision-making in areas like healthcare, finance, and logistics.\\n\\n### Challenges and Considerations\\n\\n- **Ethical Implications**: Ensuring that agentic AI operates within ethical boundaries, respects user privacy, and does not engage in biased or harmful behaviors.\\n  \\n- **Safety and Reliability**: Developing robust systems that can handle unexpected situations without causing accidents or failures, especially in critical applications like healthcare or transportation.\\n  \\n- **Transparency and Accountability**: Making the decision-making processes of agentic AI understandable to humans and establishing accountability for its actions.\\n  \\n- **Job Displacement**: Addressing the potential impact on employment as AI systems take over tasks traditionally performed by humans.\\n\\n### Future Outlook\\n\\nAgentic AI represents a significant advancement in the field of artificial intelligence, moving toward systems that can think, act, and learn with a higher degree of independence. As technology progresses, we can expect agentic AI to become more integrated into various aspects of daily life and industry, driving innovation while also necessitating careful consideration of ethical and societal implications.\\n\\nContinuous research and collaboration between technologists, policymakers, and ethicists will be essential to harness the benefits of agentic AI while mitigating its risks, ensuring that it contributes positively to society.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 982, 'prompt_tokens': 13, 'total_tokens': 995, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_79455e3cfb', 'id': 'chatcmpl-C5WxLPOF4CXtdyZbycHAXmdwUK71x', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--6a1090c0-d5f3-4005-a9d9-8693d0c5e29b-0' usage_metadata={'input_tokens': 13, 'output_tokens': 982, 'total_tokens': 995, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed with a degree of autonomy and proactive decision-making capabilities, enabling them to act independently to achieve specific goals or perform tasks on behalf of users or organizations. Unlike traditional AI systems that primarily react to inputs and follow predefined instructions, agentic AI possesses characteristics akin to agency, such as:\n",
      "\n",
      "1. **Autonomy**: The ability to operate without continuous human intervention, making decisions based on its programming and learned experiences.\n",
      "2. **Goal-Oriented Behavior**: Setting and pursuing objectives, adjusting strategies as needed to accomplish desired outcomes.\n",
      "3. **Learning and Adaptation**: Continuously improving performance through machine learning, adapting to new information and changing environments.\n",
      "4. **Interaction and Communication**: Engaging with users and other systems through natural language processing, APIs, or other interfaces to facilitate collaboration and information exchange.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Decision-Making Capability**: Agentic AI can analyze data, consider potential actions, and make informed decisions to achieve its goals.\n",
      "2. **Proactivity**: Instead of waiting for explicit instructions, it can anticipate needs or problems and take initiative to address them.\n",
      "3. **Interactivity**: Effective communication with humans and other systems to receive feedback, clarify objectives, and refine actions.\n",
      "4. **Adaptability**: Ability to learn from experiences, adjust strategies, and handle unforeseen circumstances.\n",
      "\n",
      "### Examples of Agentic AI\n",
      "\n",
      "- **Virtual Assistants**: Advanced virtual assistants like Apple's Siri, Amazon's Alexa, or Google's Assistant are evolving toward greater agency by proactively managing schedules, optimizing routes, and integrating with various services to perform tasks without explicit prompts.\n",
      "  \n",
      "- **Autonomous Vehicles**: Self-driving cars exemplify agentic AI by navigating roads, making real-time decisions based on traffic conditions, and ensuring passenger safety with minimal human input.\n",
      "  \n",
      "- **Robotic Process Automation (RPA)**: In business settings, agentic AI-powered bots can handle repetitive tasks, such as data entry, invoice processing, and customer service inquiries, autonomously improving efficiency.\n",
      "  \n",
      "- **Smart Home Systems**: AI systems that manage heating, lighting, security, and appliances by learning user preferences and adjusting settings proactively to enhance comfort and energy efficiency.\n",
      "\n",
      "### Applications and Benefits\n",
      "\n",
      "- **Efficiency and Productivity**: By automating complex and time-consuming tasks, agentic AI can significantly boost operational efficiency and allow humans to focus on higher-level activities.\n",
      "  \n",
      "- **Personalization**: Tailoring experiences, services, and recommendations based on individual preferences and behaviors, enhancing user satisfaction and engagement.\n",
      "  \n",
      "- **Decision Support**: Providing insights and recommendations to aid human decision-making in areas like healthcare, finance, and logistics.\n",
      "\n",
      "### Challenges and Considerations\n",
      "\n",
      "- **Ethical Implications**: Ensuring that agentic AI operates within ethical boundaries, respects user privacy, and does not engage in biased or harmful behaviors.\n",
      "  \n",
      "- **Safety and Reliability**: Developing robust systems that can handle unexpected situations without causing accidents or failures, especially in critical applications like healthcare or transportation.\n",
      "  \n",
      "- **Transparency and Accountability**: Making the decision-making processes of agentic AI understandable to humans and establishing accountability for its actions.\n",
      "  \n",
      "- **Job Displacement**: Addressing the potential impact on employment as AI systems take over tasks traditionally performed by humans.\n",
      "\n",
      "### Future Outlook\n",
      "\n",
      "Agentic AI represents a significant advancement in the field of artificial intelligence, moving toward systems that can think, act, and learn with a higher degree of independence. As technology progresses, we can expect agentic AI to become more integrated into various aspects of daily life and industry, driving innovation while also necessitating careful consideration of ethical and societal implications.\n",
      "\n",
      "Continuous research and collaboration between technologists, policymakers, and ethicists will be essential to harness the benefits of agentic AI while mitigating its risks, ensuring that it contributes positively to society.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nOkay, the user said, \"Hi My name is Krish.\" First, I need to respond politely. I should greet him back and acknowledge his name. Maybe add an emoji to keep it friendly. Also, offer help in case he has any questions. Keep it simple and welcoming. Let me make sure the tone is positive and approachable. Alright, that should cover it.\\n</think>\\n\\nHello Krish! 😊 Nice to meet you. How can I assist you today?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "response = model.invoke(\"Hi My name is Krish\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d414adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1117e1c00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1115755a0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x1117e1c00>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x1115755a0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I can tell you that Langsmith is a powerful and versatile open-source framework developed by the Hugging Face community. \n",
      "\n",
      "Here are some key things to know about Langsmith:\n",
      "\n",
      "**1. Focus on Productivity:** Langsmith's primary goal is to streamline the process of developing and deploying AI applications, particularly those involving large language models (LLMs). It aims to make working with LLMs more accessible and efficient for developers of all skill levels.\n",
      "\n",
      "**2. Streamlined Workflow:** Langsmith provides a user-friendly interface and a range of tools that simplify common tasks in the LLM development lifecycle. This includes tasks like:\n",
      "\n",
      "    * **Prompt Engineering:** Crafting effective prompts to elicit desired responses from LLMs.\n",
      "    * **Model Fine-tuning:** Adapting pre-trained LLMs to specific tasks or domains.\n",
      "    * **Data Management:** Handling and preparing datasets for training and evaluation.\n",
      "    * **Experiment Tracking:** Monitoring and comparing the performance of different models and configurations.\n",
      "\n",
      "**3. Open-Source Nature:** Being open-source, Langsmith encourages collaboration and community contributions. This means:\n",
      "\n",
      "    * **Transparency:** The code and documentation are publicly accessible, allowing for review and understanding.\n",
      "    * **Customization:** Developers can modify and extend Langsmith to suit their specific needs.\n",
      "    * **Community Support:** A vibrant community of users and developers provides assistance and shares knowledge.\n",
      "\n",
      "**4. Integration with Hugging Face Ecosystem:** Langsmith seamlessly integrates with the Hugging Face Hub, a platform that hosts a vast collection of pre-trained LLMs, datasets, and other AI resources. This makes it easy to access and experiment with a wide range of models and tools.\n",
      "\n",
      "**5. Accessibility:** Langsmith is designed to be accessible to a broad audience, including beginners with limited AI experience. The intuitive interface and comprehensive documentation aim to lower the barrier to entry for LLM development.\n",
      "\n",
      "**In summary, Langsmith is a valuable tool for anyone interested in exploring and building with LLMs. Its focus on productivity, open-source nature, and integration with the Hugging Face ecosystem make it a powerful and versatile framework for AI development.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like you're interested in Langsmith!  It's a fascinating project pushing the boundaries of AI development. \n",
      "\n",
      "Here's what I can tell you about Langsmith:\n",
      "\n",
      "**Langsmith: An Open-Source Framework for Building and Sharing AI Agents**\n",
      "\n",
      "Langsmith is an open-source project developed by the team at  [https://www.langsmith.com/](https://www.langsmith.com/).  \n",
      "\n",
      "Think of it as a toolkit for creating and sharing AI agents. These agents are essentially programs that can understand and respond to your requests in natural language. \n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **Modular and Extensible:** Langsmith is built on a modular design, allowing developers to easily add new capabilities and customize agents for specific tasks.\n",
      "* **Streamlined Development:** It provides a user-friendly interface and tools that simplify the process of building and training AI agents.\n",
      "* **Community-Driven:** As an open-source project, Langsmith benefits from the contributions and feedback of a large community of developers. This fosters innovation and rapid improvement.\n",
      "* **Focus on Sharing:** Langsmith emphasizes the sharing of AI agents, making it easier for developers to collaborate and build upon each other's work.\n",
      "\n",
      "**What Makes Langsmith Unique?**\n",
      "\n",
      "* **Agent-Centric:** Langsmith goes beyond traditional chatbots by focusing on building more sophisticated AI agents that can perform a wider range of tasks.\n",
      "* **Emphasis on Reusability:**  The modular design encourages developers to create reusable components, promoting efficiency and innovation.\n",
      "* **Openness and Transparency:** The open-source nature of Langsmith makes the development process more transparent and accessible to everyone.\n",
      "\n",
      "**Where Can I Learn More?**\n",
      "\n",
      "* **Langsmith Website:**  [https://www.langsmith.com/](https://www.langsmith.com/)\n",
      "* **GitHub Repository:** [https://github.com/langsmithai](https://github.com/langsmithai)\n",
      "\n",
      "I hope this overview of Langsmith is helpful! It's a project worth keeping an eye on as it continues to evolve and shape the future of AI development.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is an open-source platform designed to help developers build and deploy AI applications, particularly focusing on large language models (LLMs).', 'key_features': ['**Open-source and accessible:** Langsmith is built on open-source tools and frameworks, making it accessible to a wider range of developers.', '**Simplified LLM development:** It provides a streamlined workflow for developing, training, and deploying LLMs, abstracting away complex technical details.', \"**Modular and extensible:** Langsmith's architecture allows for easy integration with other tools and services, enabling customization and extensibility.\", '**Collaborative environment:** It fosters a collaborative environment where developers can share models, datasets, and best practices.', '**Focus on responsible AI:** Langsmith emphasizes ethical considerations and responsible AI development through features like bias detection and mitigation.'], 'website': 'https://github.com/langsml/Langsmith', 'additional_info': 'Langsmith is actively developed and maintained by the Langsmith community. Its goal is to democratize access to LLM technology and empower developers to build innovative AI applications.'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee96082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"Langsmith is an open-source platform developed by the folks at Weights & Biases that streamlines the process of fine-tuning large language models (LLMs). \\n\\nHere's a breakdown of its key features and what makes it special:\\n\\n* **Simplified Fine-Tuning:** Langsmith offers a user-friendly interface and pre-built tools that make fine-tuning LLMs much more accessible, even for those without extensive machine learning expertise.\\n* **Accelerated Training:** It leverages cutting-edge hardware acceleration techniques, including GPUs, to significantly speed up the training process.\\n* **Open and Collaborative:** Being open-source, Langsmith encourages community contributions, fostering a collaborative environment for improving and expanding the platform's capabilities.\\n* **Versatile Applications:** You can fine-tune LLMs for a wide range of tasks, such as text generation, summarization, translation, question answering, and more.\\n* **Streamlined Workflow:** Langsmith provides a comprehensive workflow for fine-tuning, including data preparation, model selection, training, evaluation, and deployment.\\n\\nEssentially, Langsmith empowers developers and researchers to easily customize and adapt powerful LLMs to their specific needs and applications.\"}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "### Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1c1802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```xml\\n<response>\\n  <name>Langsmith</name>\\n  <description>Langsmith is an open-source platform that aims to simplify and accelerate the development of AI applications powered by large language models (LLMs). It provides a modular and customizable framework for building, training, and deploying LLMs, making it accessible to a wider range of users and developers.</description>\\n  <features>\\n    <feature>Modular Design</feature>\\n    <feature>Customizable Components</feature>\\n    <feature>Streamlined Training Process</feature>\\n    <feature>Open-Source and Collaborative</feature>\\n  </features>\\n  <benefits>\\n    <benefit>Reduced Development Time</benefit>\\n    <benefit>Increased Efficiency</benefit>\\n    <benefit>Enhanced Flexibility</benefit>\\n    <benefit>Community Support</benefit>\\n  </benefits>\\n</response>\\n``` \\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 197, 'prompt_tokens': 195, 'total_tokens': 392, 'completion_time': 0.358181818, 'prompt_time': 0.004539386, 'queue_time': 0.092314287, 'total_time': 0.362721204}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--3c666162-0ad6-4d9d-aff9-074ef6f3e706-0' usage_metadata={'input_tokens': 195, 'output_tokens': 197, 'total_tokens': 392}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides tools and components for tasks such as:\\n\\n- **Chain creation:** Easily connect multiple LLMs or other tools together to build complex workflows.\\n- **Prompt management:**  Effectively manage and optimize prompts for better LLM performance.\\n- **Memory management:**  Allow your applications to remember past interactions for more coherent conversations.\\n- **Data integration:**  Connect LLMs to external data sources to enhance their knowledge and capabilities.\\n\\nLangChain aims to make it easier for developers to leverage the power of LLMs in a wide range of applications, from chatbots and question answering systems to code generation and data analysis.</answer></response>\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 39, 'total_tokens': 202, 'completion_time': 0.296363636, 'prompt_time': 0.001607739, 'queue_time': 0.091357423, 'total_time': 0.297971375}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--17ae017e-322b-4698-8255-d1bf017d9776-0' usage_metadata={'input_tokens': 39, 'output_tokens': 163, 'total_tokens': 202}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why did the scarecrow win an award?',\n",
       " 'punchline': 'Because he was outstanding in his field!'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': \"Why couldn't the bicycle stand up by itself? Because it was two tired!\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f2ec0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Apollo 13</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfed2d4",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999f98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
